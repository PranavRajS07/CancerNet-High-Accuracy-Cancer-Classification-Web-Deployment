{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lo0iKDwCwoRd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers.legacy import SGD  # Import the legacy SGD optimizer\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to '/content/drive'\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PtjHKnSzNNG",
        "outputId": "a86adabf-6f90-4c9b-d3cd-76b63b705381"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Define the paths to your train and test directories\n",
        "train_dir = '/content/drive/MyDrive/kidney_data/train'  # Replace with your actual train directory path\n",
        "test_dir = '/content/drive/MyDrive/kidney_data/train'    # Replace with your actual test directory path\n",
        "# Get the class names (subdirectories) in the train directory\n",
        "train_class_names = [class_name for class_name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, class_name))]\n",
        "# Get the class names (subdirectories) in the test directory\n",
        "test_class_names = [class_name for class_name in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, class_name))]\n",
        "# Print the class names in the train and test directories\n",
        "print(\"Class names in the train directory:\")\n",
        "print(train_class_names)\n",
        "print(\"\\nClass names in the test directory:\")\n",
        "print(test_class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMBVVWUqI-oD",
        "outputId": "a6e67ff1-7104-4acb-e78f-2ce6b4c00d4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names in the train directory:\n",
            "['Kidney_normal', 'kidney_tumor']\n",
            "\n",
            "Class names in the test directory:\n",
            "['Kidney_normal', 'kidney_tumor']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (224, 224)  # Adjust as needed\n",
        "num_classes = 2  # Change to the number of classes in your dataset\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "JHSKJ8mhzVyd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Load training and testing data using data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Use a portion of the data for validation\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh9casBNz7Pe",
        "outputId": "4bcc773b-73ba-49bc-c94c-9c256c45f9e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5270 images belonging to 2 classes.\n",
            "Found 1316 images belonging to 2 classes.\n",
            "Found 6586 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "def Inception_block(X, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4):\n",
        "    # Branch 1\n",
        "    branch1 = Conv2D(f1, (1, 1), padding='same', activation='relu')(X)\n",
        "    # Branch 2\n",
        "    branch2 = Conv2D(f2_conv1, (1, 1), padding='same', activation='relu')(X)\n",
        "    branch2 = Conv2D(f2_conv3, (3, 3), padding='same', activation='relu')(branch2)\n",
        "    # Branch 3\n",
        "    branch3 = Conv2D(f3_conv1, (1, 1), padding='same', activation='relu')(X)\n",
        "    branch3 = Conv2D(f3_conv5, (5, 5), padding='same', activation='relu')(branch3)\n",
        "    # Branch 4\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(X)\n",
        "    branch4 = Conv2D(f4, (1, 1), padding='same', activation='relu')(branch4)\n",
        "    # Concatenate the branches\n",
        "    return Concatenate(axis=-1)([branch1, branch2, branch3, branch4])"
      ],
      "metadata": {
        "id": "zKPur6C0Jw5t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GoogLeNet(input_shape=(224, 224, 3), num_classes=4):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=2, padding='valid', activation='relu')(input_layer)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # convolutional layer: filters = 64, strides = 1\n",
        "    X = Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(X)\n",
        "    # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "    X = Conv2D(filters=192, kernel_size=(3, 3), padding='same', activation='relu')(X)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # 1st Inception block\n",
        "    X = Inception_block(X, f1=64, f2_conv1=96, f2_conv3=128, f3_conv1=16, f3_conv5=32, f4=32)\n",
        "    # 2nd Inception block\n",
        "    X = Inception_block(X, f1=128, f2_conv1=128, f2_conv3=192, f3_conv1=32, f3_conv5=96, f4=64)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # 3rd Inception block\n",
        "    X = Inception_block(X, f1=192, f2_conv1=96, f2_conv3=208, f3_conv1=16, f3_conv5=48, f4=64)\n",
        "    # Extra network 1:\n",
        "    X1 = AveragePooling2D(pool_size=(5, 5), strides=3)(X)\n",
        "    X1 = Conv2D(filters=128, kernel_size=(1, 1), padding='same', activation='relu')(X1)\n",
        "    X1 = Flatten()(X1)\n",
        "    X1 = Dense(1024, activation='relu')(X1)\n",
        "    X1 = Dropout(0.7)(X1)\n",
        "    X1 = Dense(4, activation='softmax')(X1)  # Assuming you have 4 classes\n",
        "    # 4th Inception block\n",
        "    X = Inception_block(X, f1=160, f2_conv1=112, f2_conv3=224, f3_conv1=24, f3_conv5=64, f4=64)\n",
        "    # 5th Inception block\n",
        "    X = Inception_block(X, f1=128, f2_conv1=128, f2_conv3=256, f3_conv1=24, f3_conv5=64, f4=64)\n",
        "    # 6th Inception block\n",
        "    X = Inception_block(X, f1=112, f2_conv1=144, f2_conv3=288, f3_conv1=32, f3_conv5=64, f4=64)\n",
        "    # Extra network 2:\n",
        "    X2 = AveragePooling2D(pool_size=(5, 5), strides=3)(X)\n",
        "    X2 = Conv2D(filters=128, kernel_size=(1, 1), padding='same', activation='relu')(X2)\n",
        "    X2 = Flatten()(X2)\n",
        "    X2 = Dense(1024, activation='relu')(X2)\n",
        "    X2 = Dropout(0.7)(X2)\n",
        "    X2 = Dense(1000, activation='softmax')(X2)\n",
        "    # 7th Inception block\n",
        "    X = Inception_block(X, f1=256, f2_conv1=160, f2_conv3=320, f3_conv1=32, f3_conv5=128, f4=128)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # 8th Inception block\n",
        "    X = Inception_block(X, f1=256, f2_conv1=160, f2_conv3=320, f3_conv1=32, f3_conv5=128, f4=128)\n",
        "    # 9th Inception block\n",
        "    X = Inception_block(X, f1=384, f2_conv1=192, f2_conv3=384, f3_conv1=48, f3_conv5=128, f4=128)\n",
        "    # Global Average pooling layer\n",
        "    X = GlobalAveragePooling2D(name='GAPL')(X)\n",
        "    # Fully connected output layer\n",
        "    output_layer = Dense(num_classes, activation='softmax')(X)\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "# Create the GoogLeNet model\n",
        "model = GoogLeNet(input_shape=(224, 224, 3), num_classes=2)  # Assuming you have 4 classes"
      ],
      "metadata": {
        "id": "Kfl8vIbZ0Nid"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the GoogLeNet model\n",
        "model = GoogLeNet(input_shape=(224, 224, 3), num_classes=num_classes)  # Update the number of classes\n",
        "# Compile the model using the legacy SGD optimizer and 'categorical_crossentropy' loss\n",
        "sgd = SGD(learning_rate=learning_rate, decay=1e-6, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "PzOUMSXl1-E_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8387a4a-678d-433c-ca71-a8ab6f5d1258"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "165/165 [==============================] - 1040s 6s/step - loss: 0.6887 - accuracy: 0.5402 - val_loss: 0.6856 - val_accuracy: 0.5129\n",
            "Epoch 2/50\n",
            "165/165 [==============================] - 111s 673ms/step - loss: 0.5964 - accuracy: 0.6901 - val_loss: 0.4818 - val_accuracy: 0.7774\n",
            "Epoch 3/50\n",
            "165/165 [==============================] - 114s 690ms/step - loss: 0.4583 - accuracy: 0.8046 - val_loss: 0.4471 - val_accuracy: 0.8047\n",
            "Epoch 4/50\n",
            "165/165 [==============================] - 108s 657ms/step - loss: 0.3885 - accuracy: 0.8455 - val_loss: 0.4535 - val_accuracy: 0.7948\n",
            "Epoch 5/50\n",
            "165/165 [==============================] - 130s 791ms/step - loss: 0.2731 - accuracy: 0.8941 - val_loss: 0.4393 - val_accuracy: 0.8245\n",
            "Epoch 6/50\n",
            "165/165 [==============================] - 128s 775ms/step - loss: 0.2744 - accuracy: 0.8934 - val_loss: 0.4921 - val_accuracy: 0.8146\n",
            "Epoch 7/50\n",
            "165/165 [==============================] - 110s 670ms/step - loss: 0.1875 - accuracy: 0.9249 - val_loss: 0.5282 - val_accuracy: 0.8457\n",
            "Epoch 8/50\n",
            "165/165 [==============================] - 110s 664ms/step - loss: 0.1670 - accuracy: 0.9414 - val_loss: 0.5460 - val_accuracy: 0.8518\n",
            "Epoch 9/50\n",
            "165/165 [==============================] - 107s 651ms/step - loss: 0.0520 - accuracy: 0.9835 - val_loss: 0.7677 - val_accuracy: 0.8480\n",
            "Epoch 10/50\n",
            "165/165 [==============================] - 110s 668ms/step - loss: 0.0514 - accuracy: 0.9831 - val_loss: 1.0161 - val_accuracy: 0.7971\n",
            "Epoch 11/50\n",
            "165/165 [==============================] - 109s 658ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 1.0428 - val_accuracy: 0.8184\n",
            "Epoch 12/50\n",
            "165/165 [==============================] - 110s 666ms/step - loss: 0.0274 - accuracy: 0.9899 - val_loss: 2.4654 - val_accuracy: 0.7637\n",
            "Epoch 13/50\n",
            "165/165 [==============================] - 109s 661ms/step - loss: 0.0265 - accuracy: 0.9899 - val_loss: 3.3010 - val_accuracy: 0.7728\n",
            "Epoch 14/50\n",
            "165/165 [==============================] - 109s 660ms/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.9858 - val_accuracy: 0.8397\n",
            "Epoch 15/50\n",
            "165/165 [==============================] - 107s 652ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 2.1690 - val_accuracy: 0.7827\n",
            "Epoch 16/50\n",
            "165/165 [==============================] - 108s 654ms/step - loss: 0.0152 - accuracy: 0.9945 - val_loss: 1.5509 - val_accuracy: 0.8237\n",
            "Epoch 17/50\n",
            "165/165 [==============================] - 111s 674ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 2.0781 - val_accuracy: 0.8138\n",
            "Epoch 18/50\n",
            "165/165 [==============================] - 108s 656ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 1.0497 - val_accuracy: 0.8495\n",
            "Epoch 19/50\n",
            "165/165 [==============================] - 105s 635ms/step - loss: 0.0084 - accuracy: 0.9958 - val_loss: 1.7285 - val_accuracy: 0.8260\n",
            "Epoch 20/50\n",
            "165/165 [==============================] - 110s 665ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 1.8708 - val_accuracy: 0.7842\n",
            "Epoch 21/50\n",
            "165/165 [==============================] - 107s 649ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 2.3976 - val_accuracy: 0.7918\n",
            "Epoch 22/50\n",
            "165/165 [==============================] - 108s 658ms/step - loss: 3.7823e-04 - accuracy: 1.0000 - val_loss: 3.0097 - val_accuracy: 0.7812\n",
            "Epoch 23/50\n",
            "165/165 [==============================] - 106s 643ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 1.7301 - val_accuracy: 0.8062\n",
            "Epoch 24/50\n",
            "165/165 [==============================] - 109s 657ms/step - loss: 7.0555e-04 - accuracy: 1.0000 - val_loss: 1.9609 - val_accuracy: 0.8116\n",
            "Epoch 25/50\n",
            "165/165 [==============================] - 105s 639ms/step - loss: 0.0034 - accuracy: 0.9985 - val_loss: 3.5011 - val_accuracy: 0.7758\n",
            "Epoch 26/50\n",
            "165/165 [==============================] - 110s 667ms/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 2.3191 - val_accuracy: 0.8214\n",
            "Epoch 27/50\n",
            "165/165 [==============================] - 106s 643ms/step - loss: 2.1269e-04 - accuracy: 1.0000 - val_loss: 2.4209 - val_accuracy: 0.8184\n",
            "Epoch 28/50\n",
            "165/165 [==============================] - 107s 646ms/step - loss: 3.1089e-05 - accuracy: 1.0000 - val_loss: 2.9873 - val_accuracy: 0.7979\n",
            "Epoch 29/50\n",
            "165/165 [==============================] - 109s 659ms/step - loss: 3.8877e-05 - accuracy: 1.0000 - val_loss: 2.5941 - val_accuracy: 0.8100\n",
            "Epoch 30/50\n",
            "165/165 [==============================] - 107s 644ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 2.4448 - val_accuracy: 0.8047\n",
            "Epoch 31/50\n",
            "165/165 [==============================] - 107s 647ms/step - loss: 6.7062e-05 - accuracy: 1.0000 - val_loss: 2.7212 - val_accuracy: 0.7964\n",
            "Epoch 32/50\n",
            "165/165 [==============================] - 105s 637ms/step - loss: 7.6564e-05 - accuracy: 1.0000 - val_loss: 2.7843 - val_accuracy: 0.7948\n",
            "Epoch 33/50\n",
            "165/165 [==============================] - 106s 645ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 1.4004 - val_accuracy: 0.7660\n",
            "Epoch 34/50\n",
            "165/165 [==============================] - 106s 642ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 2.0575 - val_accuracy: 0.8017\n",
            "Epoch 35/50\n",
            "165/165 [==============================] - 106s 642ms/step - loss: 5.6931e-04 - accuracy: 1.0000 - val_loss: 2.1711 - val_accuracy: 0.8191\n",
            "Epoch 36/50\n",
            "165/165 [==============================] - 108s 655ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.8623 - val_accuracy: 0.8381\n",
            "Epoch 37/50\n",
            "165/165 [==============================] - 104s 633ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 1.7179 - val_accuracy: 0.8435\n",
            "Epoch 38/50\n",
            "165/165 [==============================] - 126s 763ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 3.0791 - val_accuracy: 0.7789\n",
            "Epoch 39/50\n",
            "165/165 [==============================] - 126s 764ms/step - loss: 1.2243e-04 - accuracy: 1.0000 - val_loss: 2.1259 - val_accuracy: 0.8138\n",
            "Epoch 40/50\n",
            "165/165 [==============================] - 107s 648ms/step - loss: 5.0324e-05 - accuracy: 1.0000 - val_loss: 2.5559 - val_accuracy: 0.8009\n",
            "Epoch 41/50\n",
            "165/165 [==============================] - 126s 766ms/step - loss: 2.6285e-05 - accuracy: 1.0000 - val_loss: 2.3757 - val_accuracy: 0.8070\n",
            "Epoch 42/50\n",
            "165/165 [==============================] - 106s 643ms/step - loss: 1.0890e-04 - accuracy: 1.0000 - val_loss: 2.2193 - val_accuracy: 0.8298\n",
            "Epoch 43/50\n",
            "165/165 [==============================] - 106s 640ms/step - loss: 3.7312e-05 - accuracy: 1.0000 - val_loss: 2.3497 - val_accuracy: 0.8275\n",
            "Epoch 44/50\n",
            "165/165 [==============================] - 107s 647ms/step - loss: 7.4512e-06 - accuracy: 1.0000 - val_loss: 2.4772 - val_accuracy: 0.8252\n",
            "Epoch 45/50\n",
            "165/165 [==============================] - 104s 631ms/step - loss: 6.2378e-06 - accuracy: 1.0000 - val_loss: 2.4652 - val_accuracy: 0.8207\n",
            "Epoch 46/50\n",
            "165/165 [==============================] - 126s 763ms/step - loss: 5.7181e-06 - accuracy: 1.0000 - val_loss: 2.4308 - val_accuracy: 0.8229\n",
            "Epoch 47/50\n",
            "165/165 [==============================] - 103s 627ms/step - loss: 1.4539e-05 - accuracy: 1.0000 - val_loss: 2.5201 - val_accuracy: 0.8229\n",
            "Epoch 48/50\n",
            "165/165 [==============================] - 126s 764ms/step - loss: 1.5556e-04 - accuracy: 1.0000 - val_loss: 2.4917 - val_accuracy: 0.8237\n",
            "Epoch 49/50\n",
            "165/165 [==============================] - 107s 649ms/step - loss: 1.2025e-05 - accuracy: 1.0000 - val_loss: 2.5067 - val_accuracy: 0.8237\n",
            "Epoch 50/50\n",
            "165/165 [==============================] - 105s 633ms/step - loss: 8.4109e-06 - accuracy: 1.0000 - val_loss: 2.5518 - val_accuracy: 0.8176\n",
            "206/206 [==============================] - 27s 133ms/step - loss: 0.6139 - accuracy: 0.9587\n",
            "Test Loss: 0.6138537526130676, Test Accuracy: 0.9587002992630005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjwOTViw2HSa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}