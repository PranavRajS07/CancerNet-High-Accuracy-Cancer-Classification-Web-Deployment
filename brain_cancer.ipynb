{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lo0iKDwCwoRd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers.legacy import SGD  # Import the legacy SGD optimizer\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PtjHKnSzNNG",
        "outputId": "0b93b7ce-7e26-4a02-bfc6-eefeea0d1ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to '/content/drive'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMBVVWUqI-oD",
        "outputId": "42878bea-7502-4dca-c3e3-4df0c7f151cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names in the train directory:\n",
            "['brain_tumor', 'brain_menin']\n",
            "\n",
            "Class names in the test directory:\n",
            "['brain_tumor', 'brain_menin']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Define the paths to your train and test directories\n",
        "train_dir = '/content/drive/MyDrive/brain_cancer/train'  # Replace with your actual train directory path\n",
        "test_dir = '/content/drive/MyDrive/brain_cancer/test'    # Replace with your actual test directory path\n",
        "# Get the class names (subdirectories) in the train directory\n",
        "train_class_names = [class_name for class_name in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, class_name))]\n",
        "# Get the class names (subdirectories) in the test directory\n",
        "test_class_names = [class_name for class_name in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, class_name))]\n",
        "# Print the class names in the train and test directories\n",
        "print(\"Class names in the train directory:\")\n",
        "print(train_class_names)\n",
        "print(\"\\nClass names in the test directory:\")\n",
        "print(test_class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHSKJ8mhzVyd"
      },
      "outputs": [],
      "source": [
        "image_size = (224, 224)  # Adjust as needed\n",
        "num_classes = 2  # Change to the number of classes in your dataset\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh9casBNz7Pe",
        "outputId": "d39acf81-d5be-4421-c2f3-8ba3bccdcf0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4859 images belonging to 2 classes.\n",
            "Found 1214 images belonging to 2 classes.\n",
            "Found 6073 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Load training and testing data using data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Use a portion of the data for validation\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKPur6C0Jw5t"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "def Inception_block(X, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4):\n",
        "    # Branch 1\n",
        "    branch1 = Conv2D(f1, (1, 1), padding='same', activation='relu')(X)\n",
        "    # Branch 2\n",
        "    branch2 = Conv2D(f2_conv1, (1, 1), padding='same', activation='relu')(X)\n",
        "    branch2 = Conv2D(f2_conv3, (3, 3), padding='same', activation='relu')(branch2)\n",
        "    # Branch 3\n",
        "    branch3 = Conv2D(f3_conv1, (1, 1), padding='same', activation='relu')(X)\n",
        "    branch3 = Conv2D(f3_conv5, (5, 5), padding='same', activation='relu')(branch3)\n",
        "    # Branch 4\n",
        "    branch4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(X)\n",
        "    branch4 = Conv2D(f4, (1, 1), padding='same', activation='relu')(branch4)\n",
        "    # Concatenate the branches\n",
        "    return Concatenate(axis=-1)([branch1, branch2, branch3, branch4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kfl8vIbZ0Nid"
      },
      "outputs": [],
      "source": [
        "def GoogLeNet(input_shape=(224, 224, 3), num_classes=4):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "    # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
        "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=2, padding='valid', activation='relu')(input_layer)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # convolutional layer: filters = 64, strides = 1\n",
        "    X = Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same', activation='relu')(X)\n",
        "    # convolutional layer: filters = 192, kernel_size = (3,3)\n",
        "    X = Conv2D(filters=192, kernel_size=(3, 3), padding='same', activation='relu')(X)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # 1st Inception block\n",
        "    X = Inception_block(X, f1=64, f2_conv1=96, f2_conv3=128, f3_conv1=16, f3_conv5=32, f4=32)\n",
        "    # 2nd Inception block\n",
        "    X = Inception_block(X, f1=128, f2_conv1=128, f2_conv3=192, f3_conv1=32, f3_conv5=96, f4=64)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # 3rd Inception block\n",
        "    X = Inception_block(X, f1=192, f2_conv1=96, f2_conv3=208, f3_conv1=16, f3_conv5=48, f4=64)\n",
        "    # Extra network 1:\n",
        "    X1 = AveragePooling2D(pool_size=(5, 5), strides=3)(X)\n",
        "    X1 = Conv2D(filters=128, kernel_size=(1, 1), padding='same', activation='relu')(X1)\n",
        "    X1 = Flatten()(X1)\n",
        "    X1 = Dense(1024, activation='relu')(X1)\n",
        "    X1 = Dropout(0.7)(X1)\n",
        "    X1 = Dense(4, activation='softmax')(X1)  # Assuming you have 4 classes\n",
        "    # 4th Inception block\n",
        "    X = Inception_block(X, f1=160, f2_conv1=112, f2_conv3=224, f3_conv1=24, f3_conv5=64, f4=64)\n",
        "    # 5th Inception block\n",
        "    X = Inception_block(X, f1=128, f2_conv1=128, f2_conv3=256, f3_conv1=24, f3_conv5=64, f4=64)\n",
        "    # 6th Inception block\n",
        "    X = Inception_block(X, f1=112, f2_conv1=144, f2_conv3=288, f3_conv1=32, f3_conv5=64, f4=64)\n",
        "    # Extra network 2:\n",
        "    X2 = AveragePooling2D(pool_size=(5, 5), strides=3)(X)\n",
        "    X2 = Conv2D(filters=128, kernel_size=(1, 1), padding='same', activation='relu')(X2)\n",
        "    X2 = Flatten()(X2)\n",
        "    X2 = Dense(1024, activation='relu')(X2)\n",
        "    X2 = Dropout(0.7)(X2)\n",
        "    X2 = Dense(1000, activation='softmax')(X2)\n",
        "    # 7th Inception block\n",
        "    X = Inception_block(X, f1=256, f2_conv1=160, f2_conv3=320, f3_conv1=32, f3_conv5=128, f4=128)\n",
        "    # max-pooling layer: pool_size = (3,3), strides = 2\n",
        "    X = MaxPooling2D(pool_size=(3, 3), strides=2)(X)\n",
        "    # 8th Inception block\n",
        "    X = Inception_block(X, f1=256, f2_conv1=160, f2_conv3=320, f3_conv1=32, f3_conv5=128, f4=128)\n",
        "    # 9th Inception block\n",
        "    X = Inception_block(X, f1=384, f2_conv1=192, f2_conv3=384, f3_conv1=48, f3_conv5=128, f4=128)\n",
        "    # Global Average pooling layer\n",
        "    X = GlobalAveragePooling2D(name='GAPL')(X)\n",
        "    # Fully connected output layer\n",
        "    output_layer = Dense(num_classes, activation='softmax')(X)\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "# Create the GoogLeNet model\n",
        "model = GoogLeNet(input_shape=(224, 224, 3), num_classes=2)  # Assuming you have 4 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzOUMSXl1-E_",
        "outputId": "b73c4a6e-db14-48f6-9e8e-f7a9cbf5949e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "152/152 [==============================] - 1222s 8s/step - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6876 - val_accuracy: 0.5107\n",
            "Epoch 2/50\n",
            "152/152 [==============================] - 92s 603ms/step - loss: 0.5919 - accuracy: 0.6962 - val_loss: 0.5318 - val_accuracy: 0.7348\n",
            "Epoch 3/50\n",
            "152/152 [==============================] - 92s 606ms/step - loss: 0.4943 - accuracy: 0.7580 - val_loss: 0.4770 - val_accuracy: 0.7677\n",
            "Epoch 4/50\n",
            "152/152 [==============================] - 93s 613ms/step - loss: 0.4646 - accuracy: 0.7808 - val_loss: 0.5682 - val_accuracy: 0.7109\n",
            "Epoch 5/50\n",
            "152/152 [==============================] - 90s 593ms/step - loss: 0.4513 - accuracy: 0.7860 - val_loss: 0.3832 - val_accuracy: 0.8328\n",
            "Epoch 6/50\n",
            "152/152 [==============================] - 91s 601ms/step - loss: 0.4224 - accuracy: 0.8026 - val_loss: 0.3496 - val_accuracy: 0.8418\n",
            "Epoch 7/50\n",
            "152/152 [==============================] - 90s 590ms/step - loss: 0.3476 - accuracy: 0.8535 - val_loss: 0.5442 - val_accuracy: 0.7900\n",
            "Epoch 8/50\n",
            "152/152 [==============================] - 93s 612ms/step - loss: 0.3058 - accuracy: 0.8734 - val_loss: 0.4197 - val_accuracy: 0.8229\n",
            "Epoch 9/50\n",
            "152/152 [==============================] - 92s 604ms/step - loss: 0.2512 - accuracy: 0.9008 - val_loss: 0.2567 - val_accuracy: 0.9003\n",
            "Epoch 10/50\n",
            "152/152 [==============================] - 92s 607ms/step - loss: 0.2459 - accuracy: 0.8979 - val_loss: 0.3246 - val_accuracy: 0.8583\n",
            "Epoch 11/50\n",
            "152/152 [==============================] - 90s 593ms/step - loss: 0.2388 - accuracy: 0.9068 - val_loss: 0.2095 - val_accuracy: 0.9259\n",
            "Epoch 12/50\n",
            "152/152 [==============================] - 91s 602ms/step - loss: 0.1778 - accuracy: 0.9339 - val_loss: 0.1713 - val_accuracy: 0.9300\n",
            "Epoch 13/50\n",
            "152/152 [==============================] - 90s 594ms/step - loss: 0.2083 - accuracy: 0.9166 - val_loss: 0.1631 - val_accuracy: 0.9382\n",
            "Epoch 14/50\n",
            "152/152 [==============================] - 93s 613ms/step - loss: 0.1528 - accuracy: 0.9430 - val_loss: 0.1712 - val_accuracy: 0.9325\n",
            "Epoch 15/50\n",
            "152/152 [==============================] - 90s 594ms/step - loss: 0.1328 - accuracy: 0.9518 - val_loss: 0.1549 - val_accuracy: 0.9399\n",
            "Epoch 16/50\n",
            "152/152 [==============================] - 91s 599ms/step - loss: 0.1152 - accuracy: 0.9586 - val_loss: 0.1555 - val_accuracy: 0.9357\n",
            "Epoch 17/50\n",
            "152/152 [==============================] - 89s 589ms/step - loss: 0.1096 - accuracy: 0.9593 - val_loss: 0.1039 - val_accuracy: 0.9638\n",
            "Epoch 18/50\n",
            "152/152 [==============================] - 93s 610ms/step - loss: 0.1123 - accuracy: 0.9551 - val_loss: 0.1192 - val_accuracy: 0.9506\n",
            "Epoch 19/50\n",
            "152/152 [==============================] - 89s 583ms/step - loss: 0.0985 - accuracy: 0.9654 - val_loss: 0.1295 - val_accuracy: 0.9530\n",
            "Epoch 20/50\n",
            "152/152 [==============================] - 93s 614ms/step - loss: 0.0947 - accuracy: 0.9677 - val_loss: 0.0915 - val_accuracy: 0.9695\n",
            "Epoch 21/50\n",
            "152/152 [==============================] - 89s 587ms/step - loss: 0.0854 - accuracy: 0.9706 - val_loss: 0.0971 - val_accuracy: 0.9629\n",
            "Epoch 22/50\n",
            "152/152 [==============================] - 90s 591ms/step - loss: 0.0803 - accuracy: 0.9695 - val_loss: 0.0963 - val_accuracy: 0.9687\n",
            "Epoch 23/50\n",
            "152/152 [==============================] - 92s 603ms/step - loss: 0.0730 - accuracy: 0.9724 - val_loss: 0.1234 - val_accuracy: 0.9481\n",
            "Epoch 24/50\n",
            "152/152 [==============================] - 90s 591ms/step - loss: 0.0657 - accuracy: 0.9767 - val_loss: 0.0886 - val_accuracy: 0.9671\n",
            "Epoch 25/50\n",
            "152/152 [==============================] - 91s 600ms/step - loss: 0.0647 - accuracy: 0.9778 - val_loss: 0.0790 - val_accuracy: 0.9720\n",
            "Epoch 26/50\n",
            "152/152 [==============================] - 89s 589ms/step - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.1513 - val_accuracy: 0.9555\n",
            "Epoch 27/50\n",
            "152/152 [==============================] - 93s 615ms/step - loss: 0.0650 - accuracy: 0.9759 - val_loss: 0.0651 - val_accuracy: 0.9736\n",
            "Epoch 28/50\n",
            "152/152 [==============================] - 90s 594ms/step - loss: 0.0525 - accuracy: 0.9817 - val_loss: 0.0824 - val_accuracy: 0.9720\n",
            "Epoch 29/50\n",
            "152/152 [==============================] - 92s 607ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.1787 - val_accuracy: 0.9423\n",
            "Epoch 30/50\n",
            "152/152 [==============================] - 90s 591ms/step - loss: 0.0514 - accuracy: 0.9802 - val_loss: 0.0922 - val_accuracy: 0.9671\n",
            "Epoch 31/50\n",
            "152/152 [==============================] - 93s 613ms/step - loss: 0.0528 - accuracy: 0.9794 - val_loss: 0.0594 - val_accuracy: 0.9827\n",
            "Epoch 32/50\n",
            "152/152 [==============================] - 91s 600ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0585 - val_accuracy: 0.9786\n",
            "Epoch 33/50\n",
            "152/152 [==============================] - 94s 619ms/step - loss: 0.0504 - accuracy: 0.9804 - val_loss: 0.0581 - val_accuracy: 0.9761\n",
            "Epoch 34/50\n",
            "152/152 [==============================] - 90s 592ms/step - loss: 0.0441 - accuracy: 0.9850 - val_loss: 0.0591 - val_accuracy: 0.9819\n",
            "Epoch 35/50\n",
            "152/152 [==============================] - 91s 600ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.0473 - val_accuracy: 0.9835\n",
            "Epoch 36/50\n",
            "152/152 [==============================] - 91s 599ms/step - loss: 0.0359 - accuracy: 0.9854 - val_loss: 0.0469 - val_accuracy: 0.9852\n",
            "Epoch 37/50\n",
            "152/152 [==============================] - 94s 622ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.0282 - val_accuracy: 0.9893\n",
            "Epoch 38/50\n",
            "152/152 [==============================] - 95s 628ms/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 0.1251 - val_accuracy: 0.9588\n",
            "Epoch 39/50\n",
            "152/152 [==============================] - 94s 617ms/step - loss: 0.0383 - accuracy: 0.9866 - val_loss: 0.0714 - val_accuracy: 0.9761\n",
            "Epoch 40/50\n",
            "152/152 [==============================] - 92s 609ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0768 - val_accuracy: 0.9786\n",
            "Epoch 41/50\n",
            "152/152 [==============================] - 90s 595ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 0.0478 - val_accuracy: 0.9819\n",
            "Epoch 42/50\n",
            "152/152 [==============================] - 93s 614ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0475 - val_accuracy: 0.9852\n",
            "Epoch 43/50\n",
            "152/152 [==============================] - 90s 594ms/step - loss: 0.0309 - accuracy: 0.9916 - val_loss: 0.0393 - val_accuracy: 0.9860\n",
            "Epoch 44/50\n",
            "152/152 [==============================] - 93s 612ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.0712 - val_accuracy: 0.9819\n",
            "Epoch 45/50\n",
            "152/152 [==============================] - 93s 615ms/step - loss: 0.0461 - accuracy: 0.9846 - val_loss: 0.0484 - val_accuracy: 0.9827\n",
            "Epoch 46/50\n",
            "152/152 [==============================] - 93s 611ms/step - loss: 0.0268 - accuracy: 0.9893 - val_loss: 0.0572 - val_accuracy: 0.9778\n",
            "Epoch 47/50\n",
            "152/152 [==============================] - 91s 597ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.0545 - val_accuracy: 0.9802\n",
            "Epoch 48/50\n",
            "152/152 [==============================] - 93s 611ms/step - loss: 0.0239 - accuracy: 0.9905 - val_loss: 0.0709 - val_accuracy: 0.9835\n",
            "Epoch 49/50\n",
            "152/152 [==============================] - 90s 590ms/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 0.0984 - val_accuracy: 0.9671\n",
            "Epoch 50/50\n",
            "152/152 [==============================] - 93s 614ms/step - loss: 0.0217 - accuracy: 0.9946 - val_loss: 0.0239 - val_accuracy: 0.9876\n",
            "190/190 [==============================] - 24s 126ms/step - loss: 0.0105 - accuracy: 0.9975\n",
            "Test Loss: 0.010515149682760239, Test Accuracy: 0.9975300431251526\n"
          ]
        }
      ],
      "source": [
        "# Create the GoogLeNet model\n",
        "model = GoogLeNet(input_shape=(224, 224, 3), num_classes=num_classes)  # Update the number of classes\n",
        "# Compile the model using the legacy SGD optimizer and 'categorical_crossentropy' loss\n",
        "sgd = SGD(learning_rate=learning_rate, decay=1e-6, momentum=momentum, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('modelgnet.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CpOKI1TTQF7",
        "outputId": "8cb67821-bd0e-4057-95e9-b572b4c4eec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}